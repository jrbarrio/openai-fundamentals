{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "import json\n",
    "import signal\n",
    "import datetime\n",
    "import time\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "client = OpenAI(api_key=os.getenv('OPENAI_API_KEY'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-Tuning GPT-3 Using the OpenAI API and Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = [\n",
    "\t{\n",
    "    \t\"prompt\": \"What is the capital of France?->\",\n",
    "    \t\"completion\": \"\"\" The capital of France is Paris.\\n\"\"\"\n",
    "\t},\n",
    "\t{\n",
    "    \t\"prompt\": \"What is the primary function of the heart?->\",\n",
    "    \t\"completion\": \"\"\" The primary function of the heart is to pump blood throughout the body.\\n\"\"\"\n",
    "\t},\n",
    "\t{\n",
    "    \t\"prompt\": \"What is photosynthesis?->\",\n",
    "    \t\"completion\": \"\"\" Photosynthesis is the process by which green plants and some other organisms convert sunlight into chemical energy stored in the form of glucose.\\n\"\"\"\n",
    "\t},\n",
    "\t{\n",
    "    \t\"prompt\": \"Who wrote the play 'Romeo and Juliet'?->\",\n",
    "    \t\"completion\": \"\"\" William Shakespeare wrote the play 'Romeo and Juliet'.\\n\"\"\"\n",
    "\t},\n",
    "\t{\n",
    "    \t\"prompt\": \"Which element has the atomic number 1?->\",\n",
    "    \t\"completion\": \"\"\" Hydrogen has the atomic number 1.\\n\"\"\"\n",
    "\t},\n",
    "\t{\n",
    "    \t\"prompt\": \"What is the largest planet in our solar system?->\",\n",
    "    \t\"completion\": \"\"\" Jupiter is the largest planet in our solar system.\\n\"\"\"\n",
    "\t},\n",
    "\t{\n",
    "    \t\"prompt\": \"What is the freezing point of water in Celsius?->\",\n",
    "    \t\"completion\": \"\"\" The freezing point of water in Celsius is 0 degrees.\\n\"\"\"\n",
    "\t},\n",
    "\t{\n",
    "    \t\"prompt\": \"What is the square root of 144?->\",\n",
    "    \t\"completion\": \"\"\" The square root of 144 is 12.\\n\"\"\"\n",
    "\t},\n",
    "\t{\n",
    "    \t\"prompt\": \"Who is the author of 'To Kill a Mockingbird'?->\",\n",
    "    \t\"completion\": \"\"\" The author of 'To Kill a Mockingbird' is Harper Lee.\\n\"\"\"\n",
    "\t},\n",
    "\t{\n",
    "    \t\"prompt\": \"What is the smallest unit of life?->\",\n",
    "    \t\"completion\": \"\"\" The smallest unit of life is the cell.\\n\"\"\"\n",
    "\t}\n",
    "]\n",
    "\n",
    "validation_data = [\n",
    "\t{\n",
    "    \t\"prompt\": \"Which gas do plants use for photosynthesis?->\",\n",
    "    \t\"completion\": \"\"\" Plants use carbon dioxide for photosynthesis.\\n\"\"\"\n",
    "\t},\n",
    "\t{\n",
    "    \t\"prompt\": \"What are the three primary colors of light?->\",\n",
    "    \t\"completion\": \"\"\" The three primary colors of light are red, green, and blue.\\n\"\"\"\n",
    "\t},\n",
    "\t{\n",
    "    \t\"prompt\": \"Who discovered penicillin?->\",\n",
    "    \t\"completion\": \"\"\" Sir Alexander Fleming discovered penicillin.\\n\"\"\"\n",
    "\t},\n",
    "\t{\n",
    "    \t\"prompt\": \"What is the chemical formula for water?->\",\n",
    "    \t\"completion\": \"\"\" The chemical formula for water is H2O.\\n\"\"\"\n",
    "\t},\n",
    "\t{\n",
    "    \t\"prompt\": \"What is the largest country by land area?->\",\n",
    "    \t\"completion\": \"\"\" Russia is the largest country by land area.\\n\"\"\"\n",
    "\t},\n",
    "\t{\n",
    "    \t\"prompt\": \"What is the speed of light in a vacuum?->\",\n",
    "    \t\"completion\": \"\"\" The speed of light in a vacuum is approximately 299,792 kilometers per second.\\n\"\"\"\n",
    "\t},\n",
    "\t{\n",
    "    \t\"prompt\": \"What is the currency of Japan?->\",\n",
    "    \t\"completion\": \"\"\" The currency of Japan is the Japanese Yen.\\n\"\"\"\n",
    "\t},\n",
    "\t{\n",
    "    \t\"prompt\": \"What is the smallest bone in the human body?->\",\n",
    "    \t\"completion\": \"\"\" The stapes, located in the middle ear, is the smallest bone in the human body.\\n\"\"\"\n",
    "\t}\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing...\n",
      "\n",
      "- Your file contains 10 prompt-completion pairs. In general, we recommend having at least a few hundred examples. We've found that performance tends to linearly increase for every doubling of the number of examples\n",
      "- All prompts end with suffix `?->`\n",
      "- All prompts start with prefix `Wh`\n",
      "- All completions end with suffix `.\\n`\n",
      "\n",
      "No remediations found.\n",
      "\n",
      "You can use your file for fine-tuning:\n",
      "> openai api fine_tunes.create -t \"training_data.jsonl\"\n",
      "\n",
      "After you’ve fine-tuned a model, remember that your prompt has to end with the indicator string `?->` for the model to start generating completions, rather than continuing with the prompt. Make sure to include `stop=[\".\\n\"]` so that the generated texts ends at the expected place.\n",
      "Once your model starts training, it'll approximately take 2.58 minutes to train a `curie` model, and less for `ada` and `babbage`. Queue will approximately take half an hour per job ahead of you.\n",
      "Analyzing...\n",
      "\n",
      "- Your file contains 8 prompt-completion pairs. In general, we recommend having at least a few hundred examples. We've found that performance tends to linearly increase for every doubling of the number of examples\n",
      "- All prompts end with suffix `?->`\n",
      "- All prompts start with prefix `Wh`\n",
      "- All completions end with suffix `.\\n`\n",
      "\n",
      "No remediations found.\n",
      "\n",
      "You can use your file for fine-tuning:\n",
      "> openai api fine_tunes.create -t \"validation_data.jsonl\"\n",
      "\n",
      "After you’ve fine-tuned a model, remember that your prompt has to end with the indicator string `?->` for the model to start generating completions, rather than continuing with the prompt. Make sure to include `stop=[\".\\n\"]` so that the generated texts ends at the expected place.\n",
      "Once your model starts training, it'll approximately take 2.56 minutes to train a `curie` model, and less for `ada` and `babbage`. Queue will approximately take half an hour per job ahead of you.\n"
     ]
    }
   ],
   "source": [
    "training_file_name = \"training_data.jsonl\"\n",
    "validation_file_name = \"validation_data.jsonl\"\n",
    "\n",
    "def prepare_data(dictionary_data, final_file_name): \n",
    "  with open(final_file_name, 'w') as outfile:\n",
    "    for entry in dictionary_data:\n",
    "      json.dump(entry, outfile)\n",
    "      outfile.write('\\n')\n",
    "\n",
    "prepare_data(training_data, \"training_data.jsonl\")\n",
    "prepare_data(validation_data, \"validation_data.jsonl\")\n",
    "\n",
    "!openai tools fine_tunes.prepare_data -f \"training_data.jsonl\"\n",
    "!openai tools fine_tunes.prepare_data -f \"validation_data.jsonl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training File ID: file-tV1rpaL0GnbfCVCfNz4PHyoC\n",
      "Validation File ID: file-TbVXTGAgAsIAzq9IqOYK51Kt\n"
     ]
    }
   ],
   "source": [
    "def upload_data_to_OpenAI(file_name):\n",
    "  result = client.files.create(\n",
    "    file=open(file_name, \"rb\"),\n",
    "    purpose=\"fine-tune\"\n",
    "  )\n",
    "  return result.id\n",
    "\n",
    "training_file_id = upload_data_to_OpenAI(training_file_name)\n",
    "validation_file_id = upload_data_to_OpenAI(validation_file_name)\n",
    "\n",
    "print(f\"Training File ID: {training_file_id}\")\n",
    "print(f\"Validation File ID: {validation_file_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a fine-tuning job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tunning model with jobID: ftjob-j1wI3gywlOdWwVdozcxxQEma.\n",
      "Training Response: FineTuningJob(id='ftjob-j1wI3gywlOdWwVdozcxxQEma', created_at=1705139088, error=None, fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs='auto', batch_size='auto', learning_rate_multiplier='auto'), model='davinci-002', object='fine_tuning.job', organization_id='org-IwOD4bbgH6aDvW0CURl9aBb4', result_files=[], status='validating_files', trained_tokens=None, training_file='file-tV1rpaL0GnbfCVCfNz4PHyoC', validation_file='file-TbVXTGAgAsIAzq9IqOYK51Kt')\n",
      "Training Status: validating_files\n"
     ]
    }
   ],
   "source": [
    "create_args = {\n",
    "\t\"training_file\": training_file_id,\n",
    "\t\"validation_file\": validation_file_id,\n",
    "\t\"model\": \"davinci-002\",\n",
    "\t# \"n_epochs\": 15,\n",
    "\t# \"batch_size\": 3,\n",
    "\t# \"learning_rate_multiplier\": 0.3\n",
    "}\n",
    "\n",
    "response = client.fine_tuning.jobs.create(**create_args)\n",
    "job_id = response.id\n",
    "status = response.status\n",
    "\n",
    "print(f'Fine-tunning model with jobID: {job_id}.')\n",
    "print(f\"Training Response: {response}\")\n",
    "print(f\"Training Status: {status}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtain information about the training status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Streaming events for the fine-tuning job: ftjob-j1wI3gywlOdWwVdozcxxQEma\n",
      "2024-01-13 10:46:55 The job has successfully completed\n",
      "2024-01-13 10:46:53 New fine-tuned model created: ft:davinci-002:personal::8gUtI1hR\n",
      "2024-01-13 10:46:43 Step 91/100: training loss=0.00, validation loss=0.23\n",
      "2024-01-13 10:46:41 Step 81/100: training loss=0.00, validation loss=0.01\n",
      "2024-01-13 10:46:38 Step 71/100: training loss=0.00, validation loss=2.73\n",
      "2024-01-13 10:46:36 Step 61/100: training loss=0.00, validation loss=1.33\n",
      "2024-01-13 10:46:34 Step 51/100: training loss=0.00, validation loss=0.82\n",
      "2024-01-13 10:46:31 Step 41/100: training loss=0.01, validation loss=0.15\n",
      "2024-01-13 10:46:29 Step 31/100: training loss=0.03, validation loss=0.02\n",
      "2024-01-13 10:46:24 Step 21/100: training loss=0.11, validation loss=0.53\n",
      "2024-01-13 10:46:22 Step 11/100: training loss=0.50, validation loss=0.48\n",
      "2024-01-13 10:46:19 Step 1/100: training loss=0.84, validation loss=1.42\n",
      "2024-01-13 10:45:11 Fine-tuning job started\n",
      "2024-01-13 10:45:10 Files validated, moving job to queued state\n",
      "2024-01-13 10:44:48 Validating training file: file-tV1rpaL0GnbfCVCfNz4PHyoC and validation file: file-TbVXTGAgAsIAzq9IqOYK51Kt\n",
      "2024-01-13 10:44:48 Created fine-tuning job: ftjob-j1wI3gywlOdWwVdozcxxQEma\n"
     ]
    }
   ],
   "source": [
    "def signal_handler(sig, frame):\n",
    "  status = client.fine_tuning.jobs.retrieve(job_id).status\n",
    "  print(f\"Stream interrupted. Job is still {status}.\")\n",
    "  return\n",
    "\n",
    "print(f'Streaming events for the fine-tuning job: {job_id}')\n",
    "signal.signal(signal.SIGINT, signal_handler)\n",
    "\n",
    "events = client.fine_tuning.jobs.list_events(job_id)\n",
    "try:\n",
    "  for event in events:\n",
    "    print(f'{datetime.datetime.fromtimestamp(event.created_at)} {event.message}')\n",
    "except Exception:\n",
    "  print(\"Stream interrupted (client disconnected).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check the fine-tuning job status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finetune job ftjob-j1wI3gywlOdWwVdozcxxQEma finished with status: succeeded\n",
      "Checking other finetune jobs in the subscription.\n",
      "Found 5 finetune jobs.\n"
     ]
    }
   ],
   "source": [
    "status = client.fine_tuning.jobs.retrieve(job_id).status\n",
    "if status not in [\"succeeded\", \"failed\"]:\n",
    "  print(f'Job not in terminal status: {status}. Waiting.')\n",
    "  while status not in [\"succeeded\", \"failed\"]:\n",
    "    time.sleep(2)\n",
    "    status = client.fine_tuning.jobs.retrieve(job_id).status\n",
    "    print(f'Status: {status}')\n",
    "else:\n",
    "\tprint(f'Finetune job {job_id} finished with status: {status}')\n",
    "\n",
    "print('Checking other finetune jobs in the subscription.')\n",
    "result = client.fine_tuning.jobs.list()\n",
    "print(f'Found {len(result.data)} finetune jobs.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SyncCursorPage[FineTuningJob](data=[FineTuningJob(id='ftjob-j1wI3gywlOdWwVdozcxxQEma', created_at=1705139088, error=None, fine_tuned_model='ft:davinci-002:personal::8gUtI1hR', finished_at=1705139211, hyperparameters=Hyperparameters(n_epochs=10, batch_size=1, learning_rate_multiplier=2), model='davinci-002', object='fine_tuning.job', organization_id='org-IwOD4bbgH6aDvW0CURl9aBb4', result_files=['file-u99SZ1uAuTj9ST36rlgvD5HE'], status='succeeded', trained_tokens=2240, training_file='file-tV1rpaL0GnbfCVCfNz4PHyoC', validation_file='file-TbVXTGAgAsIAzq9IqOYK51Kt'), FineTuningJob(id='ftjob-JPbKPLIp5btL65SgN4RyJDcq', created_at=1705138911, error=None, fine_tuned_model='ft:davinci-002:personal::8gUqWTGO', finished_at=1705139039, hyperparameters=Hyperparameters(n_epochs=10, batch_size=1, learning_rate_multiplier=2), model='davinci-002', object='fine_tuning.job', organization_id='org-IwOD4bbgH6aDvW0CURl9aBb4', result_files=['file-ZohYZWc1cdxouyDXoOkmPc2K'], status='succeeded', trained_tokens=2240, training_file='file-89AQBOnbfwzme3aGnuutaSKb', validation_file='file-yi4rLlKS12yDu9PJbo0eRbqX'), FineTuningJob(id='ftjob-3AkL61uJ8JOS4yfSVrMiMKo0', created_at=1705138828, error=None, fine_tuned_model='ft:davinci-002:personal::8gUp5Qki', finished_at=1705138950, hyperparameters=Hyperparameters(n_epochs=10, batch_size=1, learning_rate_multiplier=2), model='davinci-002', object='fine_tuning.job', organization_id='org-IwOD4bbgH6aDvW0CURl9aBb4', result_files=['file-0DwUkPIg2jX8hVgqJPpPDMI3'], status='succeeded', trained_tokens=2240, training_file='file-KCumAw8786tWcVH9RGVNakTX', validation_file='file-AgKVjM6kntwTiv25wNXcSvDS'), FineTuningJob(id='ftjob-9Q3slo5gHljFHEt3yCbQsHdx', created_at=1705138706, error=None, fine_tuned_model='ft:davinci-002:personal::8gUmmUCd', finished_at=1705138807, hyperparameters=Hyperparameters(n_epochs=10, batch_size=1, learning_rate_multiplier=2), model='davinci-002', object='fine_tuning.job', organization_id='org-IwOD4bbgH6aDvW0CURl9aBb4', result_files=['file-pBkqJoZqHEOLVJPC78IYs6yv'], status='succeeded', trained_tokens=2240, training_file='file-8WgVtss4j0TmJuF9WRkTo6eX', validation_file='file-1KZwCG5k4ceskQBJQTcM4DjW'), FineTuningJob(id='ftjob-caR65c5i5BUK4BnciYMDJSZW', created_at=1705138677, error=None, fine_tuned_model='ft:davinci-002:personal::8gUmff2D', finished_at=1705138800, hyperparameters=Hyperparameters(n_epochs=10, batch_size=1, learning_rate_multiplier=2), model='davinci-002', object='fine_tuning.job', organization_id='org-IwOD4bbgH6aDvW0CURl9aBb4', result_files=['file-p3VFqkAs9Fw4dopgoUOHNxbi'], status='succeeded', trained_tokens=2240, training_file='file-8WgVtss4j0TmJuF9WRkTo6eX', validation_file='file-1KZwCG5k4ceskQBJQTcM4DjW')], object='list', has_more=False)\n",
      "ft:davinci-002:personal::8gUtI1hR\n"
     ]
    }
   ],
   "source": [
    "print(result)\n",
    "\n",
    "fine_tuned_model = result.data[0].fine_tuned_model\n",
    "print(fine_tuned_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The smallest bone in the entire human body is the stapes bone of the middle\n"
     ]
    }
   ],
   "source": [
    "new_prompt = \"Which part is the smallest bone in the entire human body?\"\n",
    "answer = client.completions.create(\n",
    "  model=fine_tuned_model,\n",
    "  prompt=new_prompt\n",
    ")\n",
    "\n",
    "print(answer.choices[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The type of gas utilized by plants during the process of photosynthesis is carbon dioxide\n"
     ]
    }
   ],
   "source": [
    "new_prompt = \"\"\" Which type of gas is utilized by plants during the process of photosynthesis?\"\"\"\n",
    "answer = client.completions.create(\n",
    "  model=fine_tuned_model,\n",
    "  prompt=new_prompt\n",
    ")\n",
    "\n",
    "print(answer.choices[0].text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openai-fundamentals",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
